

task:
        vocab_id : 3 # task token in [0, 99)
        name: 'instance_segmentation'
        tokens_registered: 2
        max_seq_len : 65536 #currently set to 500 , as a start for det task stacks of 5 x100
        coord_vocab_shift : 1000 # classes are 100-999
        segm_class_shift: 500 #semantic classes can be from 500-999, other classification task label 100-499
        noise_bbox_weight : 1.0
        eos_token_weight : 0.00001
        quantization_bins : 200 #testing 2 pixels 1 bin (im_size // 2)
        top_k: 0
        top_p: 0.4
        temperature: 1.0
        loss :
                #loss : 'focal@2'


model:

        vocab_size : 2000 
        hidden_dim : 256
        size: 256 # this sets the image size for input, also the max_seq_len in decoder, make sure dataset also matches
        patch_size_sqrt: 8 #local model
        #backbone_weight : 'pretrained_weights/backbone/focalnet_tiny_srf_maskrcnn_1x.pth'
        in_channels : 3 #if use pretrained
        model_weight: 'lightning_logs/2so0mmbf/checkpoints/epoch=50-step=167331.ckpt'
        #model_weight:
        loss :

dataset:
        name : 'polygon_lesion_segmentation'
        img_size : 512
        batch_size : 8
        max_seq_len : 500 #currently set to 500 , as a start for det task stacks of 5 x100
        train_path : '/home/data_repo/INSTANCE_ICH/data2D/images/train'
        val_path : '/home/data_repo/INSTANCE_ICH/data2D/images/val'
        test_path : '/home/data_repo/INSTANCE_ICH/data2D/images/test'
        eps : 0.001


train:
        epoch : 100
